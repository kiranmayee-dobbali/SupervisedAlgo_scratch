{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\n## convert libsvm to sparse matrix\nfrom scipy.sparse import csr_matrix\nimport numpy as np\nimport statistics\nimport glob\n\ndef read_libsvm(fname, num_features=0):\n    '''\n        Reads a libsvm formatted data and outputs the training set (sparse matrix)[1],\n        the label set and the number of features. The number of features\n        can either be provided as a parameter or inferred from the data.\n\n        Example usage:\n\t\tX_train, y_train, num_features = read_libsvm('data_train')\n\t\tX_test, y_test, _ = read_libsvm('data_test', num_features)\n\n\t\t[1] https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n\t'''\n    data = []\n    y = []\n    row_ind = []\n    col_ind = []\n    with open(fname) as f:\n        lines = f.readlines()\n        for i, line in enumerate(lines):\n            elements = line.split()\n            y.append(int(elements[0]))\n            for el in elements[1:]:\n                row_ind.append(i)\n                c, v = el.split(\":\")\n                col_ind.append(int(c))\n                data.append(float(v))\n    if num_features == 0:\n        num_features = max(col_ind) + 1\n    X = csr_matrix((data, (row_ind, col_ind)), shape=(len(y), num_features+1))\n\n    return X, np.array(y), num_features\n\ndef svm(X_df, y_t , epochs=200, rate=10,C=10):\n    rgen = np.random.RandomState(0)\n    #b = rgen.uniform(-0.01,0.01,1) #initialize bias\n    s=X_df.shape[1]\n\n    weights = rgen.normal(loc=0.0, scale=0.0, size=s)\n    #w = np.zeros(len(X_df[0]))\n    transpose =[]\n    arr_acc=[]\n    error=[]\n    X_array = X_df.values\n    #dot_product = np.dot(X_array,w)\n    gamma_t=rate\n    x=0\n    t=0\n    train=0\n    for e in range(epochs):\n\n        errors=0\n        X_df.sample(frac=1)\n        for i, row in X_df.iterrows():\n            t=i+1\n            gamma_t=float(rate)/(1+((rate*t)/C))\n            #dot_product=map(lambda x,y:x*y,weights,X_array[i])\n            #print((dot_product))\n            #derived_label=reduce(lambda x,y:x+y,dot_product)\n            dot_product = np.dot(weights,X_array[i])\n            derived_label= np.sum(dot_product)\n            actual_label=y_t[i]\n            #print(derived_label,actual_label)\n            if derived_label*actual_label<=1:\n                train+=1\n                update = X_array[i]*C*gamma_t*actual_label\n                weights = weights * (1-gamma_t)\n                weights = np.add(weights,update)\n            else:\n                gamma_t=1-gamma_t\n                weights = weights*gamma_t\n\n            '''\n            condition = y_t[index]*dot_product[index]\n            #print(condition)\n            if(condition<= 0):\n                w = w - w*lr + lr*C*y_t[index]* X_array[index]\n                errors = errors+1\n            else:\n                w = (1-lr)*w\n            '''\n\n    return weights,errors\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert(col):\n    #print(col)\n    median = col.median()\n    #print(\"m\",median)\n    col[col<median]=0\n    col[col>median]=1\n    return col\n\n\n\ndef read_data():\n    X_train, y_train, num_features = read_libsvm(\"/kaggle/input/ml-fall2019-android-malware/data/data/data-splits/data.train\",0)\n    X_test, y_test, _ = read_libsvm(\"/kaggle/input/ml-fall2019-android-malware/data/data/data-splits/data.test\",0)\n    X_train_df = pd.DataFrame(X_train.toarray())\n    X_test_df= pd.DataFrame(X_test.toarray())\n    bias_array = np.full(X_train_df.shape[0],-1)\n    \n    x = X_train_df.values #returns a numpy array   \n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    X_train_df = pd.DataFrame(x_scaled)\n    \n    #X_train_df = X_train_df.apply(convert,axis=0)\n    \n    \n    X_train_df['bias']=bias_array\n    y_train = np.where(y_train==1,1,1)\n    \n    x = X_test_df.values #returns a numpy array   \n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    X_test_df = pd.DataFrame(x_scaled)\n    \n    #X_test_df = X_test_df.apply(convert,axis=0)\n    \n    y_test= np.where(y_test==1,1,-1)\n    \n    print(X_train_df.head())\n    print(y_train)\n    return X_train_df,y_train,X_test_df,y_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef accuracy(X_test_df,y_test,w_new):\n    bias_array = np.full(X_test_df.shape[0],-1)\n    X_test_df['bias']=bias_array\n    X_test_array = X_test_df.values\n\n    dot_product = np.dot(X_test_array,w_new)\n    dot_product = (np.where(dot_product>=0,1,-1))\n    x=np.count_nonzero(dot_product==y_test)\n    y=len(y_test)\n    acc = float(x/y)\n    print(\"accuracy\",x/y)\n\n    return acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef main():\n\n    X_train_df,y_train,X_test_df,y_test= read_data()\n    #change 0 to -1\n    y_train = np.where(y_train==1,1,-1)\n    ''' \n    lr =[0.1,0.01,0.001,0.0001,10]\n    C =[0.1,0.01,0.001,0.0001,10]\n    for lr_2 in lr:\n        for c in C:\n            print(lr_2,\"*******\",c)\n            w_new,errors = svm(X_train_df, y_train ,20,lr_2, c)\n            #bias_array = np.full(X_train_df.shape[0],1)\n            #X_train_df['bias']=bias_array\n            X_train_array = X_train_df.values\n            dot_product = np.dot(X_train_array,w_new)\n            dot_product = (np.where(dot_product>=0,1,1))\n            x=np.count_nonzero(dot_product==y_train)\n            y=len(y_train)\n            print(\"Train accuracy\",x/y)\n            print(\"******\")\n    '''\n    acc_list=[]\n    lr= [0.1,0.01,0.001,0.0001,10]\n    C = [0.1,0.01,0.001,0.0001,10]\n    for lr_2 in lr:\n        for c in C:\n            print(lr_2,\"*******\",c)\n            w_new,errors = svm(X_train_df, y_train ,20,lr_2, c)\n            bias_array = np.full(X_test_df.shape[0],-1)\n            X_test_df['bias']=bias_array\n            X_test_array = X_test_df.values\n            dot_product = np.dot(X_test_array,w_new)\n            dot_product = (np.where(dot_product>=0,1,-1))\n            x=np.count_nonzero(dot_product==y_test)\n            y=len(y_test)\n            print(\"Test accuracy\",x/y)\n            print(\"******\")\n            acc_list.append(x/y)\n\n\nmain()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"EVAL","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_eval, y_eval, _ = read_libsvm('/kaggle/input/ml-fall2019-android-malware/data/data/data-splits/data.eval.anon', 0)\nX_eval_df = pd.DataFrame(X_eval.toarray())    \nprint(X_eval_df.head())\nx = X_eval_df.values #returns a numpy array   \nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nX_eval_df = pd.DataFrame(x_scaled)\nX_eval_df = X_eval_df.apply(convert,axis=0)\nprint(X_eval_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_df,y_train,X_test_df,y_test= read_data()\n#change 0 to -1\nprint(X_train_df.shape)\ny_train = np.where(y_train==1,1,-1)\nw_new,errors = svm(X_train_df, y_train ,20,0.0001, 10)\nbias_array = np.full(X_eval_df.shape[0],-1)\nprint(X_eval_df.shape)\nX_eval_df['bias']=bias_array\nX_eval_df_array = X_eval_df.values\ndot_product = np.dot(X_eval_df_array,w_new)\ndot_product = (np.where(dot_product>=0,1,-1))\nlen(dot_product)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_eval_df.shape)\nprint(X_eval_df.head())\nprint(X_train_df.shape)\nprint(X_train_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_id_list=[]\nwith open(\"/kaggle/input/ml-fall2019-android-malware/data/data/data-splits/eval.id\") as f:\n    lines = f.readlines()\n    \nfor ele in lines:\n    ele=ele.rstrip(\"\\n\")\n    print(ele)\n    eval_id_list.append(ele)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dot_product= np.where(dot_product==-1,0,1)\nlen(dot_product)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_tuples = list(zip(eval_id_list, dot_product))  \n    \n# Assign data to tuples.  \nlist_of_tuples   \n  \n  \n# Converting lists of tuples into  \n# pandas Dataframe.  \ndf_new = pd.DataFrame(list_of_tuples, columns = ['example_id', 'label'])  \n     \n# Print data.  \ndf_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections, numpy\n\ncollections.Counter(dot_product)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new.to_csv(r'df_new.csv')\nfrom IPython.display import FileLink\nFileLink(r'df_new.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}